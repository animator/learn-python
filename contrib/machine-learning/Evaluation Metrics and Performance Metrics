# Machine Learning Evaluation Metrics and Performance Metrics
In the field of machine learning, evaluating the performance of a model is crucial for understanding its effectiveness in solving a particular task. There exist various metrics and techniques to assess the performance of machine learning models, each serving different purposes based on the nature of the problem being solved. In this section, we'll explore some commonly used evaluation metrics and performance measures.

## 1.Accuracy
   Accuracy is one of the most straightforward metrics used for classification problems. It measures the ratio of correctly predicted instances to the total number of instances evaluated. While accuracy is easy to understand, it might not be the best metric for imbalanced datasets where one class dominates the others.
                                                Accuracy= Total Number of Predictions/Number of Correct Predictions
​

## 2.Precision, Recall, and F1 Score
   Precision, recall, and the F1 score are commonly used metrics for evaluating classification models, especially in cases of class imbalance. Precision measures the ratio of true positives to the total predicted positives, recall measures the ratio of true positives to the total actual positives, and the F1 score is the harmonic mean of precision and recall.
                                                       - Precision= True Positives+False Positives/True Positives
                                                       - Recall= True Positives+False Negatives/True Positives
                                                       - F1Score= 2× Precision+Recall/Precision×Recall
​

​
                                 
                                                             
## 3.Confusion Matrix
   A confusion matrix provides a comprehensive summary of the performance of a classification model. It tabulates the number of true positives, true negatives, false positives, and false negatives, allowing for a more in-depth analysis of the model's performance across different classes.
                                - True Positives (TP): Instances correctly classified as positive.
                                - True Negatives (TN): Instances correctly classified as negative.
                                - False Positives (FP): Instances incorrectly classified as positive.
                                 - False Negatives (FN): Instances incorrectly classified as negative.

## 4.ROC Curve and AUC
   The Receiver Operating Characteristic (ROC) curve is a graphical representation of the true positive rate against the false positive rate at various threshold settings. The Area Under the ROC Curve (AUC) provides an aggregated measure of the model's performance across all possible classification thresholds.
## 5.Mean Absolute Error (MAE) and Mean Squared Error (MSE)
   For regression problems, Mean Absolute Error (MAE) and Mean Squared Error (MSE) are commonly used metrics to evaluate the performance of predictive models. MAE measures the average absolute difference between the predicted values and the actual values, while MSE measures the average of the squares of the errors.
                                                  MAE= 1/n∑ 

## 6.R-squared (R²)
    R-squared is a statistical measure that represents the proportion of the variance in the dependent variable that is predictable from the independent variables. It provides insight into how well the regression model fits the data, with values closer to 1 indicating a better fit.
## 7.Mean Absolute Error (MAE)
   MAE is a metric used to evaluate regression models. It represents the average of the absolute differences between predicted and actual values.
## 8. Mean Squared Error (MSE)
   MSE is another regression metric that calculates the average of the squared differences between predicted and actual values.

## 9.Root Mean Squared Error (RMSE) 
    RMSE is the square root of the MSE. It provides a measure of the spread of errors in the predictions.

These metrics provide different perspectives on model performance and are selected based on the specific characteristics of the problem at hand. It's essential to choose metrics that align with the objectives and requirements of the task.
